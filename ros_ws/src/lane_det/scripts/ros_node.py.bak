#!/usr/bin/env python3
from re import L
import time
import rospkg
import rospy
from std_msgs.msg import String
from sensor_msgs.msg import Image, CompressedImage
from cv_bridge import CvBridge, CvBridgeError
import cv2
import yaml
import numpy as np
import torch
from PIL import Image
import torchvision.transforms as transforms
# from data.constant import culane_row_anchor, tusimple_row_anchor
tusimple_row_anchor = [ 64,  68,  72,  76,  80,  84,  88,  92,  96, 100, 104, 108, 112,
            116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164,
            168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216,
            220, 224, 228, 232, 236, 240, 244, 248, 252, 256, 260, 264, 268,
            272, 276, 280, 284]
import scipy.special
import sys
sys.path.append("/home/tsari/llx/Ultra-Fast-Lane-Detection")
from model.model import parsingNet

class ImagePoint2Camera:
    """
    func  : 将图像坐标系下的点转换到相机坐标系下（假设:路面平）

    input : 内外参,误差范围
    return: 相机坐标系下的点
    """

    def __init__(self, int_param, ext_param, lane_eps_value, height):
        super(ImagePoint2Camera, self).__init__()
        self.int_param = int_param
        self.ext_param = ext_param
        self.lane_eps_value = lane_eps_value
        self.height = height

    def convert(self, point):
        point = np.array([point[0], point[1], 1.0])
        int_param_inverse = np.linalg.inv(self.int_param)
        org_camera_point = int_param_inverse @ point
        rotate_point = self.ext_param @ org_camera_point
        # apollo源代码中有异常值处理
        if abs(rotate_point[1]) < self.lane_eps_value:
            return None

        scale = self.height * 1.0 / rotate_point[1]

        # point in {camera}
        camera_point = np.array(
            [
                scale * org_camera_point[0],
                scale * org_camera_point[1],
                scale * org_camera_point[2],
            ]
        )

        return camera_point


class LaneDetection:
    """
    ros node of lane detection
    """

    def __init__(self) -> None:
        """
        load sensor config
        """
        # load internal and external param (from sensor.yaml)
        self.config_file = "/home/tsari/llx/Ultra-Fast-Lane-Detection/configs/sensors.yaml"
        with open(self.config_file, "r", encoding="utf-8") as f:
            self.cfg = yaml.load(f.read(), Loader=yaml.FullLoader)
        self.lane_num = self.cfg["lane_num"]
        self.backbone = self.cfg["backbone"]
        self.dataset = self.cfg["dataset"]
        self.griding_num = self.cfg["griding_num"]
        self.test_model = self.cfg["test_model"]
        self.data_root = self.cfg["data_root"]
        self.data_save = self.cfg["data_save"]
        self.image_W, self.image_H = self.cfg["ImageSize"]
        self.plot_path = self.cfg["plot_path"]
        self.car_center_height = self.cfg["car_center_height"]
        # 车道线的高度误差范围值
        self.lane_eps_value = self.cfg["lane_eps_value"]
        # 内参
        self.K = np.array(self.cfg["CameraMat"]["data"]).reshape(3, 3).T
        # 畸变参数
        self.D = np.array(self.cfg["DistCoeff"]["data"])
        # 外参 T_w_c
        self.R = np.array(self.cfg["CameraRotation"]["data"]).reshape(3, 3)
        self.t = np.array(self.cfg["CameraTranslation"]["data"]).reshape(3, 1)
        self.T_lidar_cam = np.vstack((np.hstack((self.R, self.t)), [0, 0, 0, 1]))

        self.T_car_lidar = np.vstack(
            (
                np.hstack(
                    (
                        np.array(self.cfg["Lidar"]["Rotation"]).reshape(3, 3),
                        np.array(self.cfg["Lidar"]["Translation"]).reshape(3, 1),
                    )
                ),
                [0, 0, 0, 1],
            )
        )

        self.T_car_cam = self.T_car_lidar @ self.T_lidar_cam
        self.T_lidar_cam0 = np.array(
            [[0, 0, 1, 0], [-1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 0, 1]]
        )

        self.T_cam0_cam = np.linalg.inv(self.T_lidar_cam0) @ self.T_lidar_cam

        self.image_topic = self.cfg["front_image_topic"]
        self.lidar_topic = self.cfg["lidar_topic"]

        self.lane_topic = self.cfg["lane_topic"]

        self.image_sub = rospy.Subscriber(
            self.image_topic, CompressedImage, self.image_callback
        )
        self.lane_pub = rospy.Publisher(self.lane_topic, String, queue_size=10)

    def elimiante_distortion(self, image):
        """
        eliminate raw image distortion
        """

        h, w = image.shape[:2]
        mapx, mapy = cv2.initUndistortRectifyMap(self.K, self.D, None, self.K, (w, h), 5)  # type: ignore
        return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)

    def inference(self, image):
        """
        inference image by trained moudle.
        """
        t0 = time.time()
        torch.backends.cudnn.benchmark = True  # type: ignore # 加速
        rospy.loginfo("   *****  inferenceing ...  *****")
        assert self.backbone in [
            "18",
            "34",
            "50",
            "101",
            "152",
            "50next",
            "101next",
            "50wide",
            "101wide",
        ]

        cls_num_per_lane = 56
        t1 = time.time()
        print("---1--- :   ", t1-t0)
        net = parsingNet(
            pretrained=False,
            backbone=self.backbone,
            cls_dim=(self.griding_num + 1, cls_num_per_lane, self.lane_num),
            use_aux=False,
        ).cuda()  # we dont need auxiliary segmentation in testing
        
        t2 = time.time()
        print("---2--- :   ", t2-t1)
        state_dict = torch.load(self.test_model, map_location="cpu")["model"]
        compatible_state_dict = {}
        for k, v in state_dict.items():
            if "module." in k:
                compatible_state_dict[k[7:]] = v
            else:
                compatible_state_dict[k] = v

        net.load_state_dict(compatible_state_dict, strict=False)
        net.eval()
        t3 = time.time()
        print("---3--- :   ", t3-t2)
        # 图像格式统一：(288, 800)，图像张量，归一化
        img_transforms = transforms.Compose(
            [
                transforms.Resize((288, 800)),
                transforms.ToTensor(),
                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
            ]
        )

        row_anchor = tusimple_row_anchor
        # 图像的分辨率大小
        img_w, img_h = self.image_W, self.image_H
        

        image = Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)) # type: ignore
        t4 = time.time()
        # 在训练时的数据维度一般都是 (batch_size, c, h, w)，
        # 而在测试时只输入一张图片(c,h,w)，所以需要扩展维度
        # add batch size channel
        print("---4--- :   ", t4-t3)
        start_time_0 = time.time()
        imgs = img_transforms(image).unsqueeze(dim=0).cuda()
        
        start_time = time.time()
        print("===> 1 :   ", start_time - start_time_0)
        with torch.no_grad():  # 测试代码不计算梯度
            out = net(imgs)  # 模型预测 输出张量：[1,101,56,4]
        
        col_sample = np.linspace(0, 800 - 1, self.griding_num)
        col_sample_w = col_sample[1] - col_sample[0]

        out_j = out[0].data.cpu().numpy()  # 数据类型转换成numpy [101,56,4]
        out_j = out_j[:, ::-1, :]  # 将第二维度倒着取[101,56,4]
        prob = scipy.special.softmax(
            out_j[:-1, :, :], axis=0
        )  # [100,56,4]softmax 计算（概率映射到0-1之间且沿着维度0概率总和=1）
        idx = np.arange(self.griding_num) + 1  # 产生 1-100
        idx = idx.reshape(-1, 1, 1)  # [100,1,1]
        loc = np.sum(prob * idx, axis=0)  # [56,4]
        out_j = np.argmax(out_j, axis=0)  # 返回最大值的索引
        loc[out_j == self.griding_num] = 0  # 若最大值的索引=griding_num，归零
        out_j = loc  # [56,4]
        
        end_time = time.time()
        
        print("inference frequency :  ", 1 / (end_time - start_time_0))
        
        t5 = time.time()
        T_cam0_cam = self.T_cam0_cam[:3, :3]
        image2camera = ImagePoint2Camera(
            self.K,
            T_cam0_cam,
            self.lane_eps_value,
            self.T_car_cam[2][3] + self.car_center_height,
        )
        
        t6 = time.time()
        print("---6--- :   ", t6-t5)
        # point = [x, y, z, 1, class] ,i 补充作4*1向量，便于计算; class 代表车道线序号
        car_points = np.empty([0, 5])
        for i in range(out_j.shape[1]):  # 遍历列# C 车道线数
            if np.sum(out_j[:, i] != 0) > 2:  # 非0单元格的数量大于2
                sum1 = np.sum(out_j[:, i] != 0)
                for k in range(out_j.shape[0]):  # 遍历行row_anchor:56
                    if out_j[k, i] > 0:
                        point = (
                            int(out_j[k, i] * col_sample_w * img_w / 800) - 1,
                            int(row_anchor[cls_num_per_lane - 1 - k] * img_h / 288) - 1,
                        )
                        # TODO: point 就是需要2D识别的车道线点
                        t6_1 = time.time()
                        camera_point = image2camera.convert(point)
                        t6_2 = time.time()
                        # print("---6_2--- :   ", t6_2-t6_1)
                        if camera_point is not None:
                            # point = [x, y, z, 1, class] ,i 补充作4*1向量，便于计算; class 代表车道线序号
                            camera_point = np.append(camera_point, 1.0)
                            car_point = self.T_car_cam @ camera_point
                            car_points = np.vstack(
                                (car_points, np.append(car_point, i))
                            )  # 加上类别
        t7 = time.time()
        print("---7--- :   ", t7-t6)
        return car_points

    def image_callback(self, image_topic):
        """
        image topic callback
        """
        raw_image = CvBridge().compressed_imgmsg_to_cv2(image_topic)
        time_0 = time.time()
        image = self.elimiante_distortion(raw_image)
        time_1 = time.time()
        print("elimiante distortion cost time :==> ", time_1-time_0)
        results = self.inference(image)
        time_2 = time.time()
        print("inference cost time :==> ", time_2-time_1)
        a = str("-2-11223749384140")
        self.lane_pub.publish(a)
        # print("results : \n", results)


def main():
    """
    main
    """
    rospy.init_node("lane_detection_node", anonymous=True)
    lane_det = LaneDetection()
    rospy.loginfo(" ***** lane_detection_node is running ***** ")
    
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")


if __name__ == "__main__":
    main()
